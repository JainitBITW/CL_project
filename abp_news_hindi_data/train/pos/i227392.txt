वेब खोज इंजन कई वेब पन्नों में संग्रहित सूचनाओं के आधार पर कार्य करतें हैं जो अपने डब्लू डब्लू डब्लू से पुनः प्राप्त करतें हैं। ये पन्नें वेब क्रोलर और के द्वारा प्राप्त हैं ; एक स्वचालित वेब ब्राउज़र जो हर कड़ी को देखता है।robots.txt के प्रयोग से निवारण किया जा सकता है प्रत्येक पन्नों के सामग्री का विश्लेषण से निर्धारित किया जा सकता है कैसे इसे अनुक्रमित किया जाए कहते हैं, से शब्द जुडा होता है) बाद के पूछ ताछ के लिए वेब पन्नों के बारें में आधार सामग्री आंकडासंचय सूचकांक में संगृहीत है कुछ खोज मशीने जैसे गूगल स्रोत पन्नों के कुछ अंश या पुरा भाग के रूप में) और साथ ही साथ वेब पन्नों के बारे में जानकारी स्टोर कर लेता है जबकि अन्य जैसे अल्ताविस्ता प्रत्येक पन्नों के प्रत्येक शब्द जो भी पातें हैं उसे संगृहीत कर लेते हैं। यह संचित पन्ना वास्तविक खोज पाठ को हमेशा पकड़े हुए है जबसे इसको वास्तविक रूप में सूचीबद्ध किया गया है इसलिए जब वर्तमान पन्ने का अंतर्वस्तु को अद्यतन करने के बाद और खोज की स्थिति ज्यादा देर तक न होने के बाद यह अत्यन्त उपयोगी हो सकता है लिंक रूट के इस समस्या को हलके रूप में समझना चाहिए और गूगल के संचालन में इसका इस्तमाल बढ़ा क्योंकि उसने खोज शब्दों को लौटे हुए वेब पृष्ठों के द्वारा उपयोगकर्ताओं के उम्मीदों को पुरा किया यह विस्मय के कम से कम सिधांत को संतुष्ट करती है आमतौर पर उपयोगकर्ता लौटे हुए पन्नों पर खोज के परिणामों की उम्मीद करता है प्रासंगिक खोज के बढने से संचित पन्ने बहुत उपयोगी हो जाते हैं, यहाँ तक की वें तथ्यों से बाहर के डाटा हो सकते हैं जो कही भी उपलब्ध नहीं है।